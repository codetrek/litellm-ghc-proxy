# GitHub Copilot Models Available
# Generated on Tue Feb  3 22:10:15 CST 2026
# Usage: Copy the desired models to your copilot-config.yaml

# Showing all models (enabled and unconfigured)
litellm_settings:
  drop_params: true

general_settings:
  database_url: postgresql://litellm:litellm@postgres:5432/litellm

model_list:
  - model_name: gpt-5-mini
    litellm_params:
      model: github_copilot/gpt-5-mini
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-5 mini (Azure OpenAI) - enabled
    # Max tokens: 64000, Context: 264000

  - model_name: gpt-5
    litellm_params:
      model: github_copilot/gpt-5
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-5 (Azure OpenAI) - enabled
    # Max tokens: 128000, Context: 400000

  - model_name: gpt-5.1
    litellm_params:
      model: github_copilot/gpt-5.1
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-5.1 (OpenAI) - enabled
    # Max tokens: 64000, Context: 264000

  - model_name: gpt-5.1-codex
    litellm_params:
      model: github_copilot/gpt-5.1-codex
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-5.1-Codex (OpenAI) - enabled
    # Max tokens: 128000, Context: 400000

  - model_name: gpt-5.1-codex-max
    litellm_params:
      model: github_copilot/gpt-5.1-codex-max
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-5.1-Codex-Max (OpenAI) - enabled
    # Max tokens: 128000, Context: 400000

  - model_name: claude-sonnet-4
    litellm_params:
      model: github_copilot/claude-sonnet-4
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # Claude Sonnet 4 (Anthropic) - enabled
    # Max tokens: 16000, Context: 216000

  - model_name: claude-sonnet-4.5
    litellm_params:
      model: github_copilot/claude-sonnet-4.5
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # Claude Sonnet 4.5 (Anthropic) - enabled
    # Max tokens: 32000, Context: 144000

  - model_name: claude-opus-4.5
    litellm_params:
      model: github_copilot/claude-opus-4.5
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # Claude Opus 4.5 (Anthropic) - enabled
    # Max tokens: 32000, Context: 160000
    litellm_settings:
      drop_params: true

  - model_name: claude-opus-4.6
    litellm_params:
      model: github_copilot/claude-opus-4.6
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # Claude Opus 4.5 (Anthropic) - enabled
    # Max tokens: 32000, Context: 160000

 - model_name: claude-opus-41
    litellm_params:
      model: github_copilot/claude-opus-41
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # Claude Opus 4.1 (Anthropic) - enabled
    # Max tokens: 16000, Context: 80000

  - model_name: claude-haiku-4.5
    litellm_params:
      model: github_copilot/claude-haiku-4.5
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # Claude Haiku 4.5 (Anthropic) - enabled
    # Max tokens: 32000, Context: 144000

  - model_name: gemini-2.5-pro
    litellm_params:
      model: github_copilot/gemini-2.5-pro
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # Gemini 2.5 Pro (Google) - enabled
    # Max tokens: 64000, Context: 128000

  - model_name: gpt-5.2
    litellm_params:
      model: github_copilot/gpt-5.2
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-5.2 (OpenAI) - enabled
    # Max tokens: 64000, Context: 264000

  - model_name: gpt-5.2-codex
    litellm_params:
      model: github_copilot/gpt-5.2-codex
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}

  - model_name: gpt-4.1
    litellm_params:
      model: github_copilot/gpt-4.1
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4.1 (Azure OpenAI) - enabled
    # Max tokens: 16384, Context: 128000

  - model_name: gpt-3.5-turbo
    litellm_params:
      model: github_copilot/gpt-3.5-turbo
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT 3.5 Turbo (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 16384

  - model_name: gpt-4o-mini
    litellm_params:
      model: github_copilot/gpt-4o-mini
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4o mini (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 128000

  - model_name: gpt-4
    litellm_params:
      model: github_copilot/gpt-4
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT 4 (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 32768

  - model_name: gpt-4o
    litellm_params:
      model: github_copilot/gpt-4o
      extra_headers: {"Editor-Version": "vscode/1.108.2", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4o (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 128000

# To use these models:
# 1. Copy desired model entries to your copilot-config.yaml
# 2. Restart LiteLLM: make stop && make start
# 3. Test with: make test
